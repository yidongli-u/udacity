{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model1 - Amissions: Accept or Reject?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Based on findings from feature selections work files: \n",
    " * successful-student-profile/feature-selection-1.ipynb \n",
    " * successful-student-profile/feature-selection-2-with-clustering.ipynb\n",
    " * successful-student-profile/feature-selection-3-with-ND-separated.ipynb\n",
    " * successful-student-profile/apps-goal-text-analysis-NB.ipynb\n",
    "\n",
    "## Let's build our first model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Output: % of graduation of each students\n",
    " * assumptions: our data visibility stops after student submit the application\n",
    "       means we know when the cohort is open, close, start; when student apply, submit; but we don't know when we are going to accept/reject and notify the student, when the student going to put down payment\n",
    "\n",
    "Approach: ND separated; application type separated\n",
    "\n",
    "Methods: Logistics Regression / Decision Tree\n",
    "\n",
    "Features:\n",
    " * user_age : account created with Udacity\n",
    " * cohort_open_to_notify\n",
    " * cohort_open_to_close\n",
    " * apply_before_start : days student apply before cohort start\n",
    " * apply_to_submit : days from apply to submit application\n",
    " * num_course_enrolled\n",
    " \n",
    " * education\n",
    " * employment\n",
    " * professional experience\n",
    " * python, java, c++, porbability, statistics, linear algebra, computer science, machine learning\n",
    " \n",
    " * mentioned programming skills / technology in goal\n",
    " \n",
    "Added:\n",
    " * ND enrolled previously than applications\n",
    " * suspended / paused: -2; cancelled / trial ended: -1; no touch: 0; enrolled: 1; graduated/term finished: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import linear_model,tree,svm,ensemble\n",
    "from sklearn.metrics import accuracy_score\n",
    "import statsmodels.api as sm\n",
    "import random\n",
    "from random import randrange\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "laurel = open('conn_laurel.txt', 'r')\n",
    "hardy = open('conn_hardy.txt', 'r')\n",
    "conn_laurel = psycopg2.connect(laurel.read())\n",
    "conn_hardy = psycopg2.connect(hardy.read())\n",
    "\n",
    "sql_apps = open('successful-student-profile-apps.sql', 'r')\n",
    "sql_courses = open('successful-student-profile-courses.sql', 'r')\n",
    "sql_nd_enrolls = open('successful-student-profile-nd-enrolls.sql','r')\n",
    "sql_questions = open('successful-student-profile-questions.sql', 'r')\n",
    "\n",
    "df_apps = pd.read_sql(sql_apps.read(),conn_laurel)\n",
    "df_courses = pd.read_sql(sql_courses.read(),conn_hardy)\n",
    "df_nd_enrolls = pd.read_sql(sql_nd_enrolls.read(),conn_laurel)\n",
    "df_questions = pd.read_sql(sql_questions.read(),conn_laurel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nd_key              application_status\n",
       "nd001-connect       paid                     1\n",
       "nd002-connect       paid                    26\n",
       "nd004-connect-reno  graduated                6\n",
       "                    paid                    14\n",
       "nd009-connect       paid                    39\n",
       "nd013               graduated               11\n",
       "                    paid                  2762\n",
       "                    term completed        1019\n",
       "nd209               graduated                4\n",
       "                    paid                  1166\n",
       "                    term completed         227\n",
       "nd889               paid                  1364\n",
       "                    term completed         146\n",
       "Name: application_id, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_apps.groupby(['nd_key','application_status'])['application_id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# geo / country -> dummies\n",
    "country = pd.get_dummies(df_apps['applicant_country'])\n",
    "df_app = pd.concat([df_apps,country],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ND previously than application\n",
    "df_nd_enrolls = df_nd_enrolls.assign(status1 = 0)\n",
    "df_nd_enrolls['status1'] = df_nd_enrolls['status'].map({'SUSPENDED':-2,'CANCELLED':-1,'GRADUATED':3,'PAUSED':-2,'ENROLLED':1,'TERM_COMPLETED':2})\n",
    "df_nd_enroll = df_nd_enrolls.groupby(['application_id','nd_key'])['status1'].max().reset_index()\n",
    "df_nd = df_nd_enroll[['application_id','nd_key','status1']].pivot(index='application_id', values='status1', columns='nd_key').fillna(0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data\n",
    "df = pd.merge(df_app,df_courses,on=['application_id','cohort_id','applicant_id','nd_key'],how='left')\n",
    "df = pd.merge(df,df_nd,on=['application_id'],how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_apps.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_apps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Based on the pivot above, let's pick nd013 as pilot to model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3792, 161)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['application_id', 'cohort_id', 'applicant_id', 'nd_key',\n",
       "       'application_type', 'applicant_country', 'applicant_geo',\n",
       "       'application_status', 'user_age', 'cohort_open_to_notify',\n",
       "       ...\n",
       "       'nd116', 'nd124', 'nd201', 'nd209', 'nd801', 'nd802', 'nd803', 'nd818',\n",
       "       'nd889', 'status'],\n",
       "      dtype='object', length=161)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nd013 = df.query(\"nd_key == 'nd013'\")\n",
    "df_nd013 = df_nd013.assign(status = df_nd013['application_status'].map({'graduated':1,'term completed':1,'paid':0}))\n",
    "print(df_nd013.shape)\n",
    "df_nd013.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cohort_id  application_status\n",
       "18         graduated               9\n",
       "           paid                  610\n",
       "           term completed        501\n",
       "220        paid                  332\n",
       "293        paid                  314\n",
       "47         graduated               2\n",
       "           paid                  463\n",
       "           term completed        349\n",
       "88         paid                  647\n",
       "           term completed        159\n",
       "89         paid                  396\n",
       "           term completed         10\n",
       "Name: application_id, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nd013.groupby(['cohort_id','application_status'])['application_id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1934, 161)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# among cohorts 18,47,88,89,220, cohort 18 and 47 are closed. cohort 88 is closing in Dec\n",
    "df_nd013 = df_nd013.loc[(df_nd013['cohort_id']=='18') | (df_nd013['cohort_id']=='47')]\n",
    "df_nd013.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# only columns we care about\n",
    "#cols = ['status','application_id','user_age','cohort_open_to_notify','cohort_open_to_close'\n",
    "#        ,'apply_before_start','apply_to_submit','num_course_enrolled']\n",
    "cols = ['status','application_id','user_age', 'cohort_open_to_notify',\n",
    "       'cohort_open_to_close', 'cohort_open_month', 'application_month',\n",
    "       'apply_before_start', 'apply_to_submit', 'num_courses',\n",
    "       'num_course_finished', 'num_course_enrolled',\n",
    "       'user_study_age'] + list(df['applicant_country'].unique()) + list(df_nd_enrolls['nd_key'].unique())\n",
    "df_nd013 = df_nd013[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from questions_responses\n",
    "# categorical\n",
    "df1 = df_nd013\n",
    "categories = {'education':'48e7b492-62b4-4d99-b596-80d68f2966ae'\n",
    "             ,'employment':'fba3666b-db04-46e9-8f3d-2a303f13e0a5'\n",
    "             ,'professional_experience':'6967091c-09c6-4455-9f1e-d0de318bacc5'\n",
    "             ,'goal':'779c3b6c-3648-423b-8d3f-8a4f36f23e2a'}\n",
    "for i,qr_id in categories.items():\n",
    "    d = df_questions.copy()\n",
    "    d[i] = 0\n",
    "    d[i] = np.where(d['question_id']==qr_id,d['response'],'0')\n",
    "    o_i = d.groupby('application_id').agg({i:'max'}).reset_index()\n",
    "    o_i = o_i[o_i.iloc[:,1] != '0']\n",
    "    o_i = o_i[o_i.iloc[:,1] != 'Other']\n",
    "    #df1 = pd.merge(df1,o_i,on=['application_id'],how='inner')\n",
    "    d_i = pd.get_dummies(o_i[i])\n",
    "    df_i = pd.concat([o_i['application_id'],d_i],axis=1)\n",
    "    df1 = pd.merge(df1,df_i,on='application_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from questions_responses\n",
    "# programming languages\n",
    "data = df1\n",
    "for i in (['python','java','cplus','probability','statistics','linear algebra','computer science','machine learning']):\n",
    "    if i == 'cplus':\n",
    "        j = 'c\\+\\+' \n",
    "    else:\n",
    "        j = i\n",
    "    d = df_questions.copy()\n",
    "    d[i] = 0\n",
    "    d[i] = np.where(d['response'].str.lower().str.contains(j),1,d[i])\n",
    "    d[i] = np.where(d['question_prompt'].str.lower().str.contains(j)&d['response'].str.match('.*[1-9].*'),1,d[i])\n",
    "    o_i = d.groupby('application_id').agg({i:'max'}).reset_index()\n",
    "    data = pd.merge(data,o_i,on=['application_id'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from goals : text\n",
    "# data\n",
    "df_goal = df_questions.loc[df_questions['question_id'].isin(['2ad03aaa-1b35-4381-9c43-907b1b4eba67','6afe0061-746b-4bd7-807c-393fe5c7599d'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_process(x):\n",
    "    import string\n",
    "    import nltk\n",
    "    from nltk.corpus import stopwords\n",
    "    stopWords = set(stopwords.words('english'))   \n",
    "    x = x.lower()\n",
    "    x.translate(str.maketrans('', '', string.punctuation))\n",
    "    return ' '.join([w for w in x.split() if w not in stopWords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mentioned ND\n",
    "nd_words = ['self driving','ai','artificial intelligence','robotics','vr','ar','machine learning','deep learning']\n",
    "# technology related?\n",
    "technology_words = ['computer science','machine learning','deep learning']\n",
    "# some other words?\n",
    "other_words = ['knowledge','learn','program','skills','experience','engineering','industry','data','field'\n",
    "              ,'technology','vision','autonomous','project','projects']\n",
    "\n",
    "df_goal = df_goal.assign(goal = df_goal['response'].apply(lambda x: text_process(x)))\n",
    "\n",
    "words = {'nd_words': ['self driving','ai','artificial intelligence','robotics','vr','ar','machine learning','deep learning']\n",
    "        ,'technology_words': ['computer science','machine learning','deep learning']\n",
    "        ,'other_words': ['knowledge','learn','program','skills','experience','engineering','industry','data','field'\n",
    "              ,'technology','vision','autonomous','project','projects']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,word_list in words.items():\n",
    "    d = df_goal.copy()\n",
    "    d[i] = 0\n",
    "    d[i] = df_goal['response'].apply(lambda x: 1 if any(w in x for w in word_list) else 0)\n",
    "    o = d.groupby('application_id').agg({i:'max'}).reset_index()\n",
    "    data = pd.merge(data,o,on=['application_id'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data\n",
    "\n",
    "# fill NaN\n",
    "data = data.fillna(0)\n",
    "data_scale = data.iloc[:,2:]\n",
    "\n",
    "# Find the min and max values for each column\n",
    "def dataset_minmax(dataset):\n",
    "    minmax = list()\n",
    "    for column in dataset:\n",
    "        col_values = [data[column][i] for i in range(dataset.shape[0])]\n",
    "        value_min = np.min(col_values)\n",
    "        value_max = np.max(col_values)\n",
    "        minmax.append([value_min, value_max])\n",
    "    return minmax\n",
    " \n",
    "# Rescale dataset columns to the range 0-1\n",
    "def normalize_dataset(dataset, minmax):\n",
    "    for row in range(dataset.shape[0]):\n",
    "        for column in range(dataset.shape[1]):\n",
    "            if (minmax[column][1] - minmax[column][0]) == 0:\n",
    "                dataset.iloc[row,column] = dataset.iloc[row,column]\n",
    "            else:\n",
    "                dataset.iloc[row,column] = (dataset.iloc[row,column] - minmax[column][0]) / (minmax[column][1] - minmax[column][0])\n",
    "\n",
    "minmax = dataset_minmax(data_scale)\n",
    "normalize_dataset(data_scale, minmax)\n",
    "data = pd.concat([data['status'],data_scale],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>user_age</th>\n",
       "      <th>cohort_open_to_notify</th>\n",
       "      <th>cohort_open_to_close</th>\n",
       "      <th>cohort_open_month</th>\n",
       "      <th>application_month</th>\n",
       "      <th>apply_before_start</th>\n",
       "      <th>apply_to_submit</th>\n",
       "      <th>num_courses</th>\n",
       "      <th>num_course_finished</th>\n",
       "      <th>...</th>\n",
       "      <th>java</th>\n",
       "      <th>cplus</th>\n",
       "      <th>probability</th>\n",
       "      <th>statistics</th>\n",
       "      <th>linear algebra</th>\n",
       "      <th>computer science</th>\n",
       "      <th>machine learning</th>\n",
       "      <th>nd_words</th>\n",
       "      <th>technology_words</th>\n",
       "      <th>other_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.746479</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.443548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.080645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>0.119403</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.403226</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.098592</td>\n",
       "      <td>0.492537</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.154930</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 179 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   status  user_age  cohort_open_to_notify  cohort_open_to_close  \\\n",
       "0       0  0.032258                    0.0                   0.0   \n",
       "1       1  0.443548                    0.0                   0.0   \n",
       "2       0  0.080645                    0.0                   0.0   \n",
       "3       0  0.403226                    0.0                   0.0   \n",
       "4       0  0.935484                    1.0                   1.0   \n",
       "\n",
       "   cohort_open_month  application_month  apply_before_start  apply_to_submit  \\\n",
       "0                1.0               1.00            0.746479         0.000000   \n",
       "1                1.0               0.50            0.028169         0.000000   \n",
       "2                1.0               1.00            0.661972         0.119403   \n",
       "3                1.0               0.75            0.098592         0.492537   \n",
       "4                0.0               0.00            0.154930         0.000000   \n",
       "\n",
       "   num_courses  num_course_finished     ...       java  cplus  probability  \\\n",
       "0     0.000000                  0.0     ...        0.0    1.0          1.0   \n",
       "1     0.027778                  0.0     ...        0.0    1.0          1.0   \n",
       "2     0.009259                  0.0     ...        0.0    1.0          1.0   \n",
       "3     0.027778                  0.0     ...        0.0    1.0          1.0   \n",
       "4     0.064815                  0.0     ...        0.0    1.0          1.0   \n",
       "\n",
       "   statistics  linear algebra  computer science  machine learning  nd_words  \\\n",
       "0         1.0             1.0               1.0               1.0       1.0   \n",
       "1         1.0             1.0               1.0               1.0       1.0   \n",
       "2         1.0             1.0               1.0               0.0       1.0   \n",
       "3         1.0             1.0               0.0               1.0       1.0   \n",
       "4         1.0             1.0               1.0               1.0       0.0   \n",
       "\n",
       "   technology_words  other_words  \n",
       "0               0.0          1.0  \n",
       "1               0.0          1.0  \n",
       "2               0.0          1.0  \n",
       "3               0.0          1.0  \n",
       "4               0.0          0.0  \n",
       "\n",
       "[5 rows x 179 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and test data set\n",
    "ratio = 0.1\n",
    "N = data.shape[0]\n",
    "index = random.sample(range(N),int(ratio*N))\n",
    "TEST = data[data.index.isin(index)]#.reset_index()\n",
    "TRAIN = data[~data.index.isin(index)]#.reset_index()\n",
    "X_train = TRAIN.iloc[:,1:]\n",
    "y_train = TRAIN.iloc[:,0]\n",
    "X_test = TEST.iloc[:,1:]\n",
    "y_test = TEST.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status\n",
       "0    963\n",
       "1    778\n",
       "Name: user_age, dtype: int64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN.groupby(['status'])['user_age'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44055140723721997"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "767/(767+974)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status\n",
       "0    110\n",
       "1     83\n",
       "Name: user_age, dtype: int64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST.groupby(['status'])['user_age'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build 5 models:\n",
    "clf1 = linear_model.LogisticRegression()\n",
    "clf2 = tree.DecisionTreeClassifier()\n",
    "clf3 = svm.SVC()\n",
    "clf4 = ensemble.RandomForestClassifier()\n",
    "clf5 = ensemble.GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_predict(learner, X_train, y_train, X_test, y_test): \n",
    "    from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "    results = {}\n",
    "    learner = learner.fit(X_train,y_train)\n",
    "    predictions_test = learner.predict(X_test)\n",
    "    predictions_train = learner.predict(X_train)\n",
    "    results['acc_train'] = accuracy_score(y_train,predictions_train)\n",
    "    results['acc_test'] = accuracy_score(y_test,predictions_test)\n",
    "    results['confusion_matrix_test'] = confusion_matrix(y_test,predictions_test)\n",
    "    try:\n",
    "        results['coef_'] = learner.coef_\n",
    "    except Exception:\n",
    "        pass\n",
    "    print(\"{} trained on {} samples.\".format(learner.__class__.__name__,X_train.shape[0]))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression trained on 1392 samples.\n",
      "LogisticRegression trained on 1393 samples.\n",
      "LogisticRegression trained on 1393 samples.\n",
      "LogisticRegression trained on 1393 samples.\n",
      "LogisticRegression trained on 1393 samples.\n",
      "DecisionTreeClassifier trained on 1392 samples.\n",
      "DecisionTreeClassifier trained on 1393 samples.\n",
      "DecisionTreeClassifier trained on 1393 samples.\n",
      "DecisionTreeClassifier trained on 1393 samples.\n",
      "DecisionTreeClassifier trained on 1393 samples.\n",
      "SVC trained on 1392 samples.\n",
      "SVC trained on 1393 samples.\n",
      "SVC trained on 1393 samples.\n",
      "SVC trained on 1393 samples.\n",
      "SVC trained on 1393 samples.\n",
      "RandomForestClassifier trained on 1392 samples.\n",
      "RandomForestClassifier trained on 1393 samples.\n",
      "RandomForestClassifier trained on 1393 samples.\n",
      "RandomForestClassifier trained on 1393 samples.\n",
      "RandomForestClassifier trained on 1393 samples.\n",
      "GradientBoostingClassifier trained on 1392 samples.\n",
      "GradientBoostingClassifier trained on 1393 samples.\n",
      "GradientBoostingClassifier trained on 1393 samples.\n",
      "GradientBoostingClassifier trained on 1393 samples.\n",
      "GradientBoostingClassifier trained on 1393 samples.\n"
     ]
    }
   ],
   "source": [
    "# 5-fold CV:\n",
    "kf = KFold(n_splits = 5, shuffle = False, random_state = 42)\n",
    "results = {}\n",
    "\n",
    "for clf in [clf1,clf2,clf3,clf4,clf5]:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    results[clf_name] = {}\n",
    "    for i,index in zip(range(kf.get_n_splits()),kf.split(X_train)):\n",
    "        x_training,x_validate = X_train.iloc[index[0],:],X_train.iloc[index[1],:]\n",
    "        y_training,y_validate = y_train.iloc[index[0]],y_train.iloc[index[1]]\n",
    "        results[clf_name][i] = train_predict(clf,x_training,y_training,x_validate,y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 LogisticRegression acc_test 0.607449856734\n",
      "0 LogisticRegression acc_test 0.528735632184\n",
      "0 LogisticRegression acc_test 0.600574712644\n",
      "0 LogisticRegression acc_test 0.566091954023\n",
      "0 LogisticRegression acc_test 0.600574712644\n",
      "1 DecisionTreeClassifier acc_test 0.512893982808\n",
      "1 DecisionTreeClassifier acc_test 0.51724137931\n",
      "1 DecisionTreeClassifier acc_test 0.520114942529\n",
      "1 DecisionTreeClassifier acc_test 0.534482758621\n",
      "1 DecisionTreeClassifier acc_test 0.522988505747\n",
      "2 SVC acc_test 0.570200573066\n",
      "2 SVC acc_test 0.543103448276\n",
      "2 SVC acc_test 0.548850574713\n",
      "2 SVC acc_test 0.594827586207\n",
      "2 SVC acc_test 0.522988505747\n",
      "3 RandomForestClassifier acc_test 0.573065902579\n",
      "3 RandomForestClassifier acc_test 0.563218390805\n",
      "3 RandomForestClassifier acc_test 0.551724137931\n",
      "3 RandomForestClassifier acc_test 0.543103448276\n",
      "3 RandomForestClassifier acc_test 0.537356321839\n",
      "4 GradientBoostingClassifier acc_test 0.561604584527\n",
      "4 GradientBoostingClassifier acc_test 0.511494252874\n",
      "4 GradientBoostingClassifier acc_test 0.603448275862\n",
      "4 GradientBoostingClassifier acc_test 0.586206896552\n",
      "4 GradientBoostingClassifier acc_test 0.566091954023\n"
     ]
    }
   ],
   "source": [
    "for k,learner in enumerate(results.keys()):\n",
    "    for i in np.arange(5):\n",
    "        print(k,learner,'acc_test',np.mean(results[learner][i]['acc_test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression mean acc:  0.580685373646\n",
      "DecisionTreeClassifier mean acc:  0.51464940882\n",
      "SVC mean acc:  0.555994137602\n",
      "RandomForestClassifier mean acc:  0.54624049007\n",
      "GradientBoostingClassifier mean acc:  0.56806474986\n"
     ]
    }
   ],
   "source": [
    "val = {}\n",
    "for k, learner in enumerate(results.keys()):\n",
    "    val[learner] = [results[learner][j]['acc_test'] for j in results[learner]]\n",
    "\n",
    "pick_a_model = {}\n",
    "for learner in val:\n",
    "    pick_a_model[learner] = sum(val[learner])/len(val[learner])\n",
    "    print(learner,\"mean acc: \",sum(val[learner])/len(val[learner]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DecisionTreeClassifier': 0.51464940881994536,\n",
       " 'GradientBoostingClassifier': 0.56806474986002709,\n",
       " 'LogisticRegression': 0.5806853736455555,\n",
       " 'RandomForestClassifier': 0.54624049007015107,\n",
       " 'SVC': 0.55599413760168626}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pick_a_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LogisticRegression'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_picked = max(pick_a_model, key=lambda k: pick_a_model[k])\n",
    "model_picked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DecisionTreeClassifier': {0: {'acc_test': 0.51002865329512892,\n",
       "   'acc_train': 1.0,\n",
       "   'confusion_matrix_test': array([[116,  83],\n",
       "          [ 88,  62]])},\n",
       "  1: {'acc_test': 0.49712643678160917,\n",
       "   'acc_train': 0.99928212491026558,\n",
       "   'confusion_matrix_test': array([[100,  89],\n",
       "          [ 86,  73]])},\n",
       "  2: {'acc_test': 0.49712643678160917,\n",
       "   'acc_train': 0.99928212491026558,\n",
       "   'confusion_matrix_test': array([[101,  90],\n",
       "          [ 85,  72]])},\n",
       "  3: {'acc_test': 0.54022988505747127,\n",
       "   'acc_train': 1.0,\n",
       "   'confusion_matrix_test': array([[111,  95],\n",
       "          [ 65,  77]])},\n",
       "  4: {'acc_test': 0.52873563218390807,\n",
       "   'acc_train': 0.99928212491026558,\n",
       "   'confusion_matrix_test': array([[119,  63],\n",
       "          [101,  65]])}},\n",
       " 'GradientBoostingClassifier': {0: {'acc_test': 0.56733524355300857,\n",
       "   'acc_train': 0.70977011494252873,\n",
       "   'confusion_matrix_test': array([[150,  49],\n",
       "          [102,  48]])},\n",
       "  1: {'acc_test': 0.51436781609195403,\n",
       "   'acc_train': 0.73223259152907394,\n",
       "   'confusion_matrix_test': array([[130,  59],\n",
       "          [110,  49]])},\n",
       "  2: {'acc_test': 0.60632183908045978,\n",
       "   'acc_train': 0.71859296482412061,\n",
       "   'confusion_matrix_test': array([[144,  47],\n",
       "          [ 90,  67]])},\n",
       "  3: {'acc_test': 0.58620689655172409,\n",
       "   'acc_train': 0.73223259152907394,\n",
       "   'confusion_matrix_test': array([[147,  59],\n",
       "          [ 85,  57]])},\n",
       "  4: {'acc_test': 0.56609195402298851,\n",
       "   'acc_train': 0.7142857142857143,\n",
       "   'confusion_matrix_test': array([[139,  43],\n",
       "          [108,  58]])}},\n",
       " 'LogisticRegression': {0: {'acc_test': 0.60744985673352436,\n",
       "   'acc_train': 0.62931034482758619,\n",
       "   'coef_': array([[-0.04989978, -0.27609451, -0.27609451, -0.49073271, -0.33553954,\n",
       "            0.14225347,  0.0889163 ,  0.10132911,  0.19335795, -0.55449138,\n",
       "            0.00411303, -0.48968772, -0.30132342, -0.30870776, -0.00310758,\n",
       "            0.2028349 ,  0.10174178,  0.2640395 ,  0.78028882, -0.69056583,\n",
       "           -0.44853738, -0.34173656, -0.09179248,  0.03700749, -0.08504332,\n",
       "            0.44872692, -0.75055922, -0.88909149,  0.        ,  0.25292713,\n",
       "            0.18687504, -0.03601884,  0.67628058,  1.06982865, -0.10695215,\n",
       "           -0.51495769, -0.43220405,  0.        ,  0.        ,  0.3141227 ,\n",
       "            0.20943116,  0.2955609 ,  0.65566166, -0.07890252,  0.07016523,\n",
       "            0.        ,  0.        ,  0.        , -0.62798069, -0.56666029,\n",
       "           -0.48207721, -0.63283316, -0.33802547,  0.        ,  0.        ,\n",
       "           -0.2638298 , -0.39163254,  0.        ,  0.        ,  0.30997374,\n",
       "            0.        ,  0.19674279,  0.        ,  0.17576769,  1.03018622,\n",
       "           -0.15757812,  0.34006619,  0.        ,  0.35303601,  0.166665  ,\n",
       "            0.        ,  0.        ,  0.        ,  0.        ,  0.36187462,\n",
       "            0.        ,  0.42343079,  0.        , -0.28388052,  0.        ,\n",
       "           -0.14097398, -0.39044176,  0.        ,  0.40920125, -0.26762466,\n",
       "            0.        ,  0.23058155,  0.        ,  0.        ,  0.04543761,\n",
       "           -0.183817  ,  0.35488308,  0.        ,  0.        , -0.38170755,\n",
       "            0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "            0.        , -0.36541383,  0.34167724,  0.        ,  0.        ,\n",
       "            0.        ,  0.33371781,  0.        ,  0.        ,  0.        ,\n",
       "            0.        , -0.36189668,  0.        ,  0.        ,  0.        ,\n",
       "            1.12819177, -0.08923865,  0.77713869,  0.65274085, -0.40580269,\n",
       "           -0.59706007, -0.37251803, -0.18956448, -0.08312366, -0.31654647,\n",
       "           -0.00684159,  0.0975904 , -0.39031628,  0.        , -0.04617946,\n",
       "            0.        ,  0.6148633 ,  0.        ,  0.3082584 ,  0.        ,\n",
       "            0.        , -0.3067523 ,  0.22081267,  0.        ,  0.        ,\n",
       "            0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "            0.        ,  0.        ,  0.        , -0.17269731, -0.27272239,\n",
       "            0.19367744,  0.57103038, -0.21750437, -0.35699271, -0.62496979,\n",
       "           -0.28830435, -0.1493018 , -0.10798661, -0.1649638 , -0.140954  ,\n",
       "           -0.0929605 , -0.25996231, -0.13862926, -0.06713917, -0.07319566,\n",
       "           -0.83778351, -0.07619091,  1.08962807,  0.28836948,  0.04852854,\n",
       "           -0.09061681,  0.43626661,  0.11100498, -0.2432195 ,  0.32185584,\n",
       "           -0.18438537,  0.00610367,  0.25386557]]),\n",
       "   'confusion_matrix_test': array([[161,  38],\n",
       "          [ 99,  51]])},\n",
       "  1: {'acc_test': 0.52873563218390807,\n",
       "   'acc_train': 0.65972720746590097,\n",
       "   'coef_': array([[ 0.04167056, -0.33005007, -0.33005007, -0.20507086, -1.03035674,\n",
       "            0.79588503,  0.14381192,  0.57901725,  0.32267976, -0.54966094,\n",
       "            0.04383679, -0.4705986 , -0.44113663, -0.42676357, -0.03152758,\n",
       "            0.30091628,  0.03199608,  0.18528175,  1.24229889, -1.30036315,\n",
       "           -0.42658971,  0.16099121,  0.2156966 ,  0.28266908,  0.13169341,\n",
       "            0.51274528, -0.75313194, -0.43139218,  0.        ,  0.58660128,\n",
       "            0.41927553,  0.00661475,  0.83368581,  0.7226645 , -0.05820614,\n",
       "           -0.10839879, -0.17103959, -0.62375599,  0.        , -0.14878885,\n",
       "           -0.23122437,  0.29469168,  0.48988567, -0.25863122,  0.34680107,\n",
       "            0.        ,  0.        ,  0.        , -0.54730104, -0.65760783,\n",
       "           -0.40301045, -0.30329968, -0.37629069,  0.        ,  0.        ,\n",
       "            0.69019681, -0.57577097,  0.51655198,  0.10931055,  0.58524871,\n",
       "            0.        ,  0.23929493,  0.        ,  0.60635898,  0.97385952,\n",
       "           -0.27009317,  0.36373147,  0.        ,  0.4031474 , -0.5710702 ,\n",
       "            0.        ,  0.        ,  0.        ,  0.        ,  0.36409421,\n",
       "            0.        ,  0.        , -0.4952172 , -0.34125679,  0.        ,\n",
       "           -0.1361457 ,  0.        ,  0.        ,  0.        , -0.2711896 ,\n",
       "            0.        ,  0.        ,  0.        ,  0.        , -0.36643044,\n",
       "           -0.48966404,  0.        ,  0.        ,  0.        , -0.34938673,\n",
       "            0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "            0.        , -0.39400469,  0.32612183,  0.        ,  0.        ,\n",
       "            0.        ,  0.24045148,  0.        ,  0.        ,  0.        ,\n",
       "            0.        , -0.28871016,  0.        ,  0.        ,  0.        ,\n",
       "            1.281803  , -0.18860769,  0.9440486 ,  0.16593491, -0.29926213,\n",
       "           -0.37022384, -0.27437555, -0.04498396, -0.23091116, -0.66070046,\n",
       "            0.18931282,  0.07162097,  0.15839658,  0.        ,  0.01629328,\n",
       "            0.        ,  0.49897874,  0.        , -0.32561439,  0.        ,\n",
       "            0.        , -0.53512093,  0.3447827 ,  0.        ,  0.        ,\n",
       "            0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "            0.        ,  0.        ,  0.        , -0.26935231, -0.67438462,\n",
       "            0.18043806,  0.46177706, -0.02790817, -0.26425731, -0.66333505,\n",
       "           -0.34113042, -0.18080211, -0.03809899, -0.03021503,  0.05349877,\n",
       "           -0.28144855, -0.23885713, -0.57689955, -0.312108  , -0.04424418,\n",
       "           -0.51383385, -0.36344293,  0.62302298,  0.02223216,  0.1250262 ,\n",
       "            0.22871147,  0.22871147, -0.03260178, -0.30216961,  0.48718048,\n",
       "           -0.12662047,  0.10523117, -0.03055763]]),\n",
       "   'confusion_matrix_test': array([[134,  55],\n",
       "          [109,  50]])},\n",
       "  2: {'acc_test': 0.60057471264367812,\n",
       "   'acc_train': 0.63029432878679115,\n",
       "   'coef_': array([[-0.18135972, -0.24637271, -0.24637271, -0.5974534 , -0.24550302,\n",
       "            0.02931488,  0.07964541,  0.36393899,  0.07389562, -0.50996555,\n",
       "           -0.08433524, -0.40487733, -0.18253943, -0.576705  ,  0.03021567,\n",
       "            0.25118828, -0.06772345,  0.24020109,  0.7987782 , -0.98178901,\n",
       "           -0.46579241,  0.24082021,  0.31502478,  0.19443285, -0.06946578,\n",
       "            0.15805327, -0.74309496, -0.52623658,  0.        ,  0.59990847,\n",
       "            0.26397219,  0.08235374,  0.68515048,  1.06639681, -0.63468929,\n",
       "           -0.15957984, -0.89210034, -0.57706458,  0.        ,  0.02608278,\n",
       "           -0.3618665 ,  0.2719594 ,  0.67294977,  0.37140328,  0.35310165,\n",
       "            0.        ,  0.        ,  0.        , -0.59328865, -0.6334403 ,\n",
       "           -0.72503528, -0.49369223, -0.3664122 ,  0.        ,  0.        ,\n",
       "           -0.18684283, -0.55288377,  0.48054487,  0.22199749,  0.22206522,\n",
       "            0.        ,  0.08052298,  0.        ,  0.55308881,  0.34260425,\n",
       "            0.25369694,  0.4754285 ,  0.        ,  0.        , -0.1158708 ,\n",
       "            0.        ,  0.        ,  0.        ,  0.        ,  0.37914467,\n",
       "            0.        ,  0.37708707, -0.40193857, -0.31297422,  0.        ,\n",
       "           -0.16151472, -0.36086153,  0.        ,  0.39174182,  0.        ,\n",
       "            0.        ,  0.20285551,  0.        ,  0.        ,  0.04110675,\n",
       "            0.31984709,  0.35733573,  0.        ,  0.        , -0.26865213,\n",
       "            0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "            0.        , -0.39199812,  0.35186802,  0.        ,  0.        ,\n",
       "            0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "            0.        , -0.3078249 ,  0.        ,  0.        ,  0.        ,\n",
       "            1.26682726, -0.39166492,  0.48927099,  0.91904104, -0.43061318,\n",
       "           -0.38671213, -0.4429938 ,  0.00692902, -0.06561723, -0.16978635,\n",
       "           -0.03390665, -0.53180602, -0.26089269,  0.        ,  0.15881511,\n",
       "            0.        ,  0.4036105 ,  0.        ,  0.25605012,  0.        ,\n",
       "            0.        , -0.37111097,  0.16657861,  0.        ,  0.        ,\n",
       "            0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "            0.        ,  0.        ,  0.        , -0.23918029, -0.18043186,\n",
       "            0.17564341,  0.58353938, -0.00493442, -0.41545147, -0.47118271,\n",
       "           -0.2787581 , -0.52917341, -0.20704906, -0.15754837, -0.18656273,\n",
       "           -0.25062207, -0.04204389, -0.29609886, -0.08222337, -0.03537946,\n",
       "           -0.70821055, -0.19384459,  1.0395474 ,  0.38900334,  0.10895242,\n",
       "           -0.12603504,  0.35539045,  0.17793069,  0.11446612,  0.40963511,\n",
       "           -0.13135283,  0.15931427,  0.12968032]]),\n",
       "   'confusion_matrix_test': array([[128,  63],\n",
       "          [ 76,  81]])},\n",
       "  3: {'acc_test': 0.56609195402298851,\n",
       "   'acc_train': 0.63819095477386933,\n",
       "   'coef_': array([[-0.49696632, -0.15599394, -0.15599394, -0.44032554, -0.50007877,\n",
       "           -0.06466431, -0.28422054,  0.49680761,  0.67777066, -0.36495263,\n",
       "           -0.08093124, -0.59260835, -0.5287559 , -0.47057232,  0.01846741,\n",
       "            0.21098545,  0.00280293,  0.08680997,  0.61289638, -0.9459747 ,\n",
       "           -0.52061952,  0.0696977 ,  0.41360135,  0.35046367,  0.15746336,\n",
       "            0.86873184, -0.58727186, -0.80245758,  0.        ,  0.05122063,\n",
       "            0.48522262, -0.01413326,  0.76847408,  0.86342725, -0.15636841,\n",
       "           -0.16505263, -0.12557473, -0.71992748,  0.        , -0.29149429,\n",
       "           -0.27620745,  0.27477493,  0.41815699,  0.42672436,  0.05842129,\n",
       "            0.        ,  0.        ,  0.        , -0.39817491, -0.56102247,\n",
       "           -1.12626481,  0.01533553, -0.40237949,  0.        ,  0.        ,\n",
       "            0.04280279, -0.63390829,  0.44504388,  0.13444008,  0.83293303,\n",
       "            0.        , -0.15207223,  0.        ,  0.57075487,  0.96334168,\n",
       "           -0.59841657,  0.81871873,  0.        ,  0.39123658, -0.42545755,\n",
       "            0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "            0.        ,  0.34737856, -0.46273197, -0.38463   ,  0.        ,\n",
       "            0.        , -0.3570615 ,  0.        ,  0.47932769, -0.20288721,\n",
       "            0.        ,  0.18681011,  0.        ,  0.        ,  0.30748623,\n",
       "           -0.19714655,  0.30873305,  0.        ,  0.        , -0.33491083,\n",
       "            0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "            0.        , -0.39431478,  0.31781733,  0.        ,  0.        ,\n",
       "            0.        ,  0.25599952,  0.        ,  0.        ,  0.        ,\n",
       "            0.        , -0.32442372,  0.        ,  0.        ,  0.        ,\n",
       "            1.24387181, -0.03368488,  0.57841879,  0.48891524, -0.70288668,\n",
       "           -0.26338156, -0.48442241, -0.35355631, -0.17286207, -0.26661823,\n",
       "            0.04358824, -0.00385457,  0.19885407,  0.        ,  0.01431453,\n",
       "            0.        ,  0.57822424,  0.        ,  0.63507456,  0.        ,\n",
       "            0.        , -0.08742556,  0.07746098,  0.        ,  0.        ,\n",
       "            0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "            0.        ,  0.        ,  0.        , -0.13060405, -0.21127886,\n",
       "            0.33468805,  0.69812974, -0.20331983, -0.45768563, -0.71060035,\n",
       "           -0.55949819, -0.23430044,  0.01940206,  0.03847029, -0.00559341,\n",
       "           -0.14274368, -0.50585474, -0.26670389, -0.12589879,  0.08862975,\n",
       "           -0.63025139, -0.14651175,  0.65175221,  0.08503661,  0.27188937,\n",
       "           -0.06850456,  0.55426483, -0.10240701, -0.29349639,  0.43732377,\n",
       "            0.1799985 , -0.04195774, -0.04494105]]),\n",
       "   'confusion_matrix_test': array([[142,  64],\n",
       "          [ 87,  55]])},\n",
       "  4: {'acc_test': 0.60057471264367812,\n",
       "   'acc_train': 0.64824120603015079,\n",
       "   'coef_': array([[-0.20895163, -0.3019537 , -0.3019537 , -0.45107149, -0.65300183,\n",
       "            0.39755587,  0.09510677,  0.01760291, -0.03261068, -0.00888428,\n",
       "           -0.03386853, -0.56960075, -0.38856422, -0.60432476, -0.04764683,\n",
       "            0.21529391,  0.20116279, -0.0311385 ,  0.8248096 , -0.83034698,\n",
       "           -0.42295971,  0.04649019,  0.20561072,  0.18484977, -0.11077927,\n",
       "            0.40577712, -0.38135608, -0.52152292,  0.        ,  0.39643019,\n",
       "            0.31731413, -0.0407561 ,  0.8276067 ,  0.84571101, -0.31494663,\n",
       "            0.33312056, -0.45777622, -0.65320877,  0.        , -0.25325988,\n",
       "           -1.12414004,  0.        ,  0.01287879,  0.13729156,  0.21183873,\n",
       "            0.        ,  0.        ,  0.        , -0.37250768, -0.686628  ,\n",
       "           -0.59321002, -0.59775737,  0.        ,  0.        ,  0.        ,\n",
       "            0.03607428, -0.30769436,  0.44058452,  0.14821412,  0.18497623,\n",
       "            0.        ,  0.55674768,  0.        ,  0.42374409,  0.875441  ,\n",
       "           -0.20096548,  0.59734276,  0.        ,  0.44338856, -0.62273451,\n",
       "            0.        ,  0.        ,  0.        ,  0.        ,  0.33247826,\n",
       "            0.        ,  0.37227668, -0.48356274,  0.        ,  0.        ,\n",
       "           -0.14107557, -0.40633096,  0.        ,  0.45128217, -0.27279271,\n",
       "            0.        ,  0.22391826,  0.        ,  0.        ,  0.00965502,\n",
       "           -0.22893997,  0.36238601,  0.        ,  0.        ,  0.        ,\n",
       "            0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "            0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "            0.        ,  0.28880646,  0.        ,  0.        ,  0.        ,\n",
       "            0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "            1.05831292,  0.07022857,  0.8089423 ,  0.48756947, -0.73430505,\n",
       "           -0.42616232, -0.22606169,  0.14244394, -0.42300929, -0.29076934,\n",
       "           -0.32999863, -0.24789116, -0.25799397,  0.        ,  0.0673975 ,\n",
       "            0.        ,  0.49697174,  0.        ,  0.39544348,  0.        ,\n",
       "            0.        , -0.28526824, -0.02476332,  0.        ,  0.        ,\n",
       "            0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "            0.        ,  0.        ,  0.        , -0.13248355, -0.32470367,\n",
       "            0.20424008,  0.56179304,  0.08392637, -0.19777251, -0.3223525 ,\n",
       "           -0.15901223, -0.28017997, -0.02227445, -0.19746417, -0.00665305,\n",
       "           -0.20286388, -0.32376963, -0.13886303, -0.04889585,  0.09098009,\n",
       "           -0.44791287, -0.03084795,  0.81755898, -0.16942341,  0.16164726,\n",
       "           -0.1610458 ,  0.43318143,  0.14136934, -0.13576722,  0.41822703,\n",
       "           -0.00751395,  0.07377534, -0.01710103]]),\n",
       "   'confusion_matrix_test': array([[141,  41],\n",
       "          [ 98,  68]])}},\n",
       " 'RandomForestClassifier': {0: {'acc_test': 0.54154727793696278,\n",
       "   'acc_train': 0.98132183908045978,\n",
       "   'confusion_matrix_test': array([[143,  56],\n",
       "          [104,  46]])},\n",
       "  1: {'acc_test': 0.56321839080459768,\n",
       "   'acc_train': 0.97774587221823406,\n",
       "   'confusion_matrix_test': array([[133,  56],\n",
       "          [ 96,  63]])},\n",
       "  2: {'acc_test': 0.55172413793103448,\n",
       "   'acc_train': 0.97989949748743721,\n",
       "   'confusion_matrix_test': array([[129,  62],\n",
       "          [ 94,  63]])},\n",
       "  3: {'acc_test': 0.53735632183908044,\n",
       "   'acc_train': 0.98636037329504667,\n",
       "   'confusion_matrix_test': array([[145,  61],\n",
       "          [100,  42]])},\n",
       "  4: {'acc_test': 0.53735632183908044,\n",
       "   'acc_train': 0.97702799712849964,\n",
       "   'confusion_matrix_test': array([[136,  46],\n",
       "          [115,  51]])}},\n",
       " 'SVC': {0: {'acc_test': 0.57020057306590255,\n",
       "   'acc_train': 0.55172413793103448,\n",
       "   'confusion_matrix_test': array([[199,   0],\n",
       "          [150,   0]])},\n",
       "  1: {'acc_test': 0.5431034482758621,\n",
       "   'acc_train': 0.55850681981335248,\n",
       "   'confusion_matrix_test': array([[189,   0],\n",
       "          [159,   0]])},\n",
       "  2: {'acc_test': 0.54885057471264365,\n",
       "   'acc_train': 0.55707106963388375,\n",
       "   'confusion_matrix_test': array([[191,   0],\n",
       "          [157,   0]])},\n",
       "  3: {'acc_test': 0.59482758620689657,\n",
       "   'acc_train': 0.54917444364680545,\n",
       "   'confusion_matrix_test': array([[206,   0],\n",
       "          [141,   1]])},\n",
       "  4: {'acc_test': 0.52298850574712641,\n",
       "   'acc_train': 0.56353194544149321,\n",
       "   'confusion_matrix_test': array([[182,   0],\n",
       "          [166,   0]])}}}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.60744985673352436,\n",
       " 1: 0.52873563218390807,\n",
       " 2: 0.60057471264367812,\n",
       " 3: 0.56609195402298851,\n",
       " 4: 0.60057471264367812}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pick_highest_test_acc = {}\n",
    "for i in range(len(results[model_picked])):\n",
    "    pick_highest_test_acc[i] = results[model_picked][i]['acc_test']\n",
    "pick_highest_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highest_test_acc_picked = max(pick_highest_test_acc, key=lambda k: pick_highest_test_acc[k])\n",
    "highest_test_acc_picked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_coef = results[model_picked][highest_test_acc_picked]['coef_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do a Stochastic Gradient Descent on Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a prediction with coefficients\n",
    "def predict(row,coef):\n",
    "    from math import exp\n",
    "    yhat = coef[0]\n",
    "    for i in range(len(row)-1):\n",
    "        yhat += coef[i+1] * row[i]\n",
    "    return 1.0 / (1.0 + exp(-yhat))\n",
    "\n",
    "# estimate logistic regression coefficients using stochastic gradient descent\n",
    "def coef_sgd(train,l_rate,n_epoch):\n",
    "    coef = [0.0 for i in range(train.shape[1])]\n",
    "    for epoch in range(n_epoch):\n",
    "        for row in range(train.shape[0]):\n",
    "            yhat = predict(train.iloc[row,1:],coef)\n",
    "            error = train.iloc[row,0] - yhat\n",
    "            coef[0] = coef[0] + l_rate*error*yhat*(1.0-yhat)\n",
    "            for i in range(train.shape[1]-1):\n",
    "                coef[i+1] = coef[i+1] + l_rate*error*yhat*(1.0-yhat)*train.iloc[row,i]\n",
    "    return coef\n",
    "\n",
    "# Linear Regression Algorithm With Stochastic Gradient Descent\n",
    "def logistic_regression(train, test, l_rate, n_epoch):\n",
    "    predictions = list()\n",
    "    coef = coef_sgd(train, l_rate, n_epoch)\n",
    "    for row in range(test.shape[0]):\n",
    "        yhat = predict(test.iloc[row,1:],coef)\n",
    "        yhat = round(yhat)\n",
    "        predictions.append(yhat)\n",
    "    return(coef,predictions)\n",
    "\n",
    "# Evaluate an algorithm using a cross validation split\n",
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "    folds = cross_validation_split(dataset, n_folds)\n",
    "    scores = list()\n",
    "    for fold in folds:\n",
    "        train_set = list(folds)\n",
    "        train_set.remove(fold)\n",
    "        train_set = sum(train_set, [])\n",
    "        test_set = list()\n",
    "        for row in fold:\n",
    "            row_copy = list(row)\n",
    "            test_set.append(row_copy)\n",
    "            row_copy[-1] = None\n",
    "        predicted = algorithm(train_set, test_set, *args)\n",
    "        actual = [row[-1] for row in fold]\n",
    "        accuracy = accuracy_metric(actual, predicted)\n",
    "        scores.append(accuracy)\n",
    "    return scores\n",
    "\n",
    "# Split a dataset into k folds\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "    dataset_split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset) / n_folds)\n",
    "    for i in range(n_folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "    return dataset_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_rate = 0.01\n",
    "n_epoch = 10\n",
    "predict_sgd = logistic_regression(TRAIN,TEST,l_rate,n_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.049900</td>\n",
       "      <td>-0.526459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.276095</td>\n",
       "      <td>8.468038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.276095</td>\n",
       "      <td>-1.568854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.490733</td>\n",
       "      <td>-1.610255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.335540</td>\n",
       "      <td>-1.610255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>1.083796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.088916</td>\n",
       "      <td>0.800953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.101329</td>\n",
       "      <td>0.403081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.193358</td>\n",
       "      <td>-0.200690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.554491</td>\n",
       "      <td>-0.010147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.004113</td>\n",
       "      <td>-0.010939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.489688</td>\n",
       "      <td>-0.003678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.301323</td>\n",
       "      <td>-0.137101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.308708</td>\n",
       "      <td>-1.167454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.003108</td>\n",
       "      <td>0.005151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.202835</td>\n",
       "      <td>-0.085148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.101742</td>\n",
       "      <td>0.007238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.264039</td>\n",
       "      <td>0.454334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.780289</td>\n",
       "      <td>0.026364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.690566</td>\n",
       "      <td>0.012193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.448537</td>\n",
       "      <td>0.020718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.341737</td>\n",
       "      <td>-0.031503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.091792</td>\n",
       "      <td>-0.048869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.037007</td>\n",
       "      <td>0.036789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.085043</td>\n",
       "      <td>0.000098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.448727</td>\n",
       "      <td>0.006328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.750559</td>\n",
       "      <td>-0.031921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.889091</td>\n",
       "      <td>0.020992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.252927</td>\n",
       "      <td>-0.049694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>-0.272722</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.193677</td>\n",
       "      <td>-0.987070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.571030</td>\n",
       "      <td>-0.094571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>-0.217504</td>\n",
       "      <td>0.269898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>-0.356993</td>\n",
       "      <td>0.328425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>-0.624970</td>\n",
       "      <td>0.071101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>-0.288304</td>\n",
       "      <td>-0.358815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>-0.149302</td>\n",
       "      <td>-0.104422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>-0.107987</td>\n",
       "      <td>-0.206275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>-0.164964</td>\n",
       "      <td>0.017050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>-0.140954</td>\n",
       "      <td>-0.228224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>-0.092961</td>\n",
       "      <td>-0.032697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>-0.259962</td>\n",
       "      <td>0.105865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>-0.138629</td>\n",
       "      <td>-0.174042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>-0.067139</td>\n",
       "      <td>-0.197361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>-0.073196</td>\n",
       "      <td>-0.233696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>-0.837784</td>\n",
       "      <td>0.273537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>-0.076191</td>\n",
       "      <td>-0.059424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1.089628</td>\n",
       "      <td>-0.098458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.288369</td>\n",
       "      <td>-0.426363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0.048529</td>\n",
       "      <td>-0.264470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>-0.090617</td>\n",
       "      <td>0.058627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.436267</td>\n",
       "      <td>-0.163277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.111005</td>\n",
       "      <td>-0.320236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>-0.243219</td>\n",
       "      <td>-0.320236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.321856</td>\n",
       "      <td>-0.201381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>-0.184385</td>\n",
       "      <td>-0.480667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.006104</td>\n",
       "      <td>0.626161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.253866</td>\n",
       "      <td>-0.512529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.303489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         0\n",
       "0   -0.049900 -0.526459\n",
       "1   -0.276095  8.468038\n",
       "2   -0.276095 -1.568854\n",
       "3   -0.490733 -1.610255\n",
       "4   -0.335540 -1.610255\n",
       "5    0.142253  1.083796\n",
       "6    0.088916  0.800953\n",
       "7    0.101329  0.403081\n",
       "8    0.193358 -0.200690\n",
       "9   -0.554491 -0.010147\n",
       "10   0.004113 -0.010939\n",
       "11  -0.489688 -0.003678\n",
       "12  -0.301323 -0.137101\n",
       "13  -0.308708 -1.167454\n",
       "14  -0.003108  0.005151\n",
       "15   0.202835 -0.085148\n",
       "16   0.101742  0.007238\n",
       "17   0.264039  0.454334\n",
       "18   0.780289  0.026364\n",
       "19  -0.690566  0.012193\n",
       "20  -0.448537  0.020718\n",
       "21  -0.341737 -0.031503\n",
       "22  -0.091792 -0.048869\n",
       "23   0.037007  0.036789\n",
       "24  -0.085043  0.000098\n",
       "25   0.448727  0.006328\n",
       "26  -0.750559 -0.031921\n",
       "27  -0.889091  0.020992\n",
       "28   0.000000  0.006971\n",
       "29   0.252927 -0.049694\n",
       "..        ...       ...\n",
       "149 -0.272722  0.000000\n",
       "150  0.193677 -0.987070\n",
       "151  0.571030 -0.094571\n",
       "152 -0.217504  0.269898\n",
       "153 -0.356993  0.328425\n",
       "154 -0.624970  0.071101\n",
       "155 -0.288304 -0.358815\n",
       "156 -0.149302 -0.104422\n",
       "157 -0.107987 -0.206275\n",
       "158 -0.164964  0.017050\n",
       "159 -0.140954 -0.228224\n",
       "160 -0.092961 -0.032697\n",
       "161 -0.259962  0.105865\n",
       "162 -0.138629 -0.174042\n",
       "163 -0.067139 -0.197361\n",
       "164 -0.073196 -0.233696\n",
       "165 -0.837784  0.273537\n",
       "166 -0.076191 -0.059424\n",
       "167  1.089628 -0.098458\n",
       "168  0.288369 -0.426363\n",
       "169  0.048529 -0.264470\n",
       "170 -0.090617  0.058627\n",
       "171  0.436267 -0.163277\n",
       "172  0.111005 -0.320236\n",
       "173 -0.243219 -0.320236\n",
       "174  0.321856 -0.201381\n",
       "175 -0.184385 -0.480667\n",
       "176  0.006104  0.626161\n",
       "177  0.253866 -0.512529\n",
       "178       NaN  0.303489\n",
       "\n",
       "[179 rows x 2 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_coef = predict_sgd[0]\n",
    "pd.concat([pd.DataFrame(start_coef).T,pd.DataFrame(end_coef)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49222797927461137"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "T = confusion_matrix(y_test,predict_sgd[1])\n",
    "(T[0][0]+T[1][1])/(T[0][0]+T[0][1]+T[1][0]+T[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[57, 35],\n",
       "       [63, 38]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[[161,  38],\n",
    " [ 99,  51]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-188-7274c996c29e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart_coef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-156-e6d2126fb2e5>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(row, coef)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoef\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0myhat\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcoef\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "for row in range(TEST.shape[0]):\n",
    "    yhat = predict(TEST.iloc[row,1:],start_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-190-ee9445660980>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstart_coef\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'matrix' is not defined"
     ]
    }
   ],
   "source": [
    "matrix(X_test)*start_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty range for randrange()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-9549dd51d20a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0ml_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mn_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mevaluate_algorithm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogistic_regression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_folds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-110-d4e036973bfc>\u001b[0m in \u001b[0;36mevaluate_algorithm\u001b[0;34m(dataset, algorithm, n_folds, *args)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Evaluate an algorithm using a cross validation split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_algorithm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_folds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mfolds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_folds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-110-d4e036973bfc>\u001b[0m in \u001b[0;36mcross_validation_split\u001b[0;34m(dataset, n_folds)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mfold_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_copy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0mfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mdataset_split\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/random.py\u001b[0m in \u001b[0;36mrandrange\u001b[0;34m(self, start, stop, step, _int)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mistart\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_randbelow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mistart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"empty range for randrange()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;31m# stop argument supplied.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: empty range for randrange()"
     ]
    }
   ],
   "source": [
    "# evaluate algorithm\n",
    "n_folds = 5\n",
    "l_rate = 0.1\n",
    "n_epoch = 100\n",
    "evaluate_algorithm(data, logistic_regression, n_folds, l_rate, n_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_copy = list(data)\n",
    "len(dataset_copy)\n",
    "randrange(179)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a prediction with coefficients\n",
    "def predict(row, coefficients):\n",
    "\tyhat = coefficients[0]\n",
    "\tfor i in range(len(row)-1):\n",
    "\t\tyhat += coefficients[i + 1] * row[i]\n",
    "\treturn 1.0 / (1.0 + exp(-yhat))\n",
    " \n",
    "# Estimate logistic regression coefficients using stochastic gradient descent\n",
    "def coefficients_sgd(train, l_rate, n_epoch):\n",
    "\tcoef = [0.0 for i in range(len(train[0]))]\n",
    "\tfor epoch in range(n_epoch):\n",
    "\t\tfor row in train:\n",
    "\t\t\tyhat = predict(row, coef)\n",
    "\t\t\terror = row[-1] - yhat\n",
    "\t\t\tcoef[0] = coef[0] + l_rate * error * yhat * (1.0 - yhat)\n",
    "\t\t\tfor i in range(len(row)-1):\n",
    "\t\t\t\tcoef[i + 1] = coef[i + 1] + l_rate * error * yhat * (1.0 - yhat) * row[i]\n",
    "\treturn coef\n",
    " \n",
    "# Linear Regression Algorithm With Stochastic Gradient Descent\n",
    "def logistic_regression(train, test, l_rate, n_epoch):\n",
    "\tpredictions = list()\n",
    "\tcoef = coefficients_sgd(train, l_rate, n_epoch)\n",
    "\tfor row in test:\n",
    "\t\tyhat = predict(row, coef)\n",
    "\t\tyhat = round(yhat)\n",
    "\t\tpredictions.append(yhat)\n",
    "\treturn(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "clf = linear_model.LogisticRegression()\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X_train.describe().T\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "logit = sm.Logit(y_train,X_train)\n",
    "result = logit.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network - keras\n",
    "import keras\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dropout(.1))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(.1))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compiling the model using a loss function and an optimizer.\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "model.fit(X_train.as_matrix(), y_train, epochs=300, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test.as_matrix(), y_test, verbose=0)\n",
    "print(\"Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
