{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn_laurel = psycopg2.connect(\"dbname='analytics' user='analytics' host='analytics.cv90snkxh2gd.us-west-2.rds.amazonaws.com' password='!TgP$Ol9Z&6QhKW0tmn9mOW5rYT2J8'\")\n",
    "#cur_laurel = conn_laurel.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn_hardy = psycopy2.connect(\"dbname='analytics' user='awsdatapipeline' host='udacity-segment.c2zpsqalam7o.us-west-2.redshift.amazonaws.com' password='Know.it.13818'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql_apps = \"select a.id as application_id,a.applicant_id---,a.first_name,a.last_name,a.email\\\n",
    "                  ,coalesce(a.applicant_geo,'Unknown') AS applicant_geo\\\n",
    "                  ,coalesce(a.applicant_country,'Unknown') AS applicant_country\\\n",
    "                  ,case when response like '%Android Developer%' then 'AND'\\\n",
    "                        when response like '%Front-End Web Developer%' then 'FEND'\\\n",
    "                        when response like '%Mobile Web Specialist%' then 'MWSND'\\\n",
    "                        when response like '%Android Basics%' then 'ABND'\\\n",
    "                   else 'No Selection' end as nd_interest\\\n",
    "                   from applications a\\\n",
    "                   left join admissions.question_responses b on a.id = b.application_id\\\n",
    "                   where a.submitted_at is not null and a.cohort_id = 'eu-google-sep-2017'\\\n",
    "                     and b.question_id = '1ce91eb3-4ba3-47e7-9b69-8387a994b12c';\"\n",
    "df = pd.read_sql(sql_apps,conn_laurel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql_apps = '''select application_id,applicant_id,first_name,last_name,email\n",
    "      ,country_at_registration,country_at_registration_geo\n",
    "      ,ip_address,ip_country,ip_city\n",
    "      ,application_created_at,account_started_at\n",
    "      ,count(distinct case when status in ('GRADUATED','TERM_COMPLETED','ENROLLED') then nd_key end) as nd_count\n",
    "      ,avg(case when concept_sum = 0 then 0 else round(100.0*num_concepts_completed/concept_sum,2) end) as avg_nd_concept_completion_rate\n",
    "      ,max(case when concept_sum = 0 then 0 else round(100.0*num_concepts_completed/concept_sum,2) end) as max_nd_concept_completion_rate\n",
    "      ,avg(case when project_sum = 0 then 0 else round(100.0*num_projects_submitted/project_sum,2) end) as avg_nd_project_completion_rate\n",
    "      ,max(case when project_sum = 0 then 0 else round(100.0*num_projects_submitted/project_sum,2) end) as max_nd_project_completion_rate\n",
    "      ,course_num as course_count\n",
    "      ,finished_course_num as finished_course_count\n",
    "from test_yidong.google_scholarship_nov_apps\n",
    "group by application_id,applicant_id,first_name,last_name,email\n",
    "      ,country_at_registration,conuntry_at_registration_geo\n",
    "      ,ip_address,ip_country,ip_city\n",
    "      ,application_created_at,account_started_at\n",
    "      ,course_num,finished_course_num\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql_questions = \"select application_id,question_id,response\\\n",
    "                 from admissions.question_responses qr\\\n",
    "                 inner join applications a on qr.application_id = a.id\\\n",
    "                 where a.cohort_id = 'us-google-nov-2017'\\\n",
    "                   and a.submitted_at is not null\\\n",
    "                   and question_id != '1ce91eb3-4ba3-47e7-9b69-8387a994b12c';\"\n",
    "df_2 = pd.read_sql(sql_questions,conn_laurel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "questions_pivot = df_2.pivot(index='application_id', values='response', columns='question_prompt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joined = df.join(questions_pivot, on='application_id')\n",
    "final = joined[joined.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joined.to_csv('us-google-nov-2017-apps.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#writer = pd.ExcelWriter('google_scholarship_sep2017_apps_by_track.xlsx',engine='xlsxwriter')\n",
    "\n",
    "#for i in list(final['nd_interest'].unique()):\n",
    "    #data = final.loc[final['nd_interest']==i]\n",
    "    #data.to_excel(writer,sheet_name=i,index=False)\n",
    "    #writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in list(final['nd_interest'].unique()):\n",
    "    data = final.loc[final['nd_interest']==i]\n",
    "    data.to_csv('{0}.csv'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fend = final.loc[final['nd_interest']=='FEND']\n",
    "\n",
    "writer = pd.ExcelWriter('google_scholarship_sep2017_fend.xlsx',engine='xlsxwriter')\n",
    "\n",
    "for i in list(fend['applicant_geo'].unique()):\n",
    "    data = final.loc[final['applicant_geo']==i]\n",
    "    data.to_excel(writer,sheet_name=i,index=False)\n",
    "    \n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fend = final.loc[final['nd_interest']=='FEND']\n",
    "\n",
    "for i in list(fend['applicant_geo'].unique()):\n",
    "    data = fend.loc[fend['applicant_geo']==i]\n",
    "    data.to_csv('FEND-{0}.csv'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "LOAD source is not supported. (Hint: only S3 or DynamoDB or EMR based load is allowed)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-d53bc4b1ba34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'HubSpot-Imports.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_expert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy_sql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: LOAD source is not supported. (Hint: only S3 or DynamoDB or EMR based load is allowed)\n"
     ]
    }
   ],
   "source": [
    "#this works fastest\n",
    "\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "#laurel\n",
    "#conn = psycopg2.connect(\"dbname='analytics' user='analytics' host='analytics.cv90snkxh2gd.us-west-2.rds.amazonaws.com' password='!TgP$Ol9Z&6QhKW0tmn9mOW5rYT2J8'\")\n",
    "\n",
    "#harday\n",
    "conn = psycopg2.connect(\"dbname='analytics' user='awsdatapipeline' host='udacity-segment.c2zpsqalam7o.us-west-2.redshift.amazonaws.com' port='5439' password='Know.it.13818'\")\n",
    "#conn = psycopg2.connect(\"dbname='analytics' user='udacian' host='udacity-segment.c2zpsqalam7o.us-west-2.redshift.amazonaws.com' port='5439' password='AYEe&mtihMqtXQbWR2xgWrhmKzd6]F'\")\n",
    "\n",
    "cur = conn.cursor()\n",
    "#copy_sql = '''\n",
    " #           COPY \"analytics_tables\".uconnect_lead_form_outside_sources FROM stdin WITH CSV HEADER\n",
    "  #          DELIMITER as ','\n",
    "   #     '''\n",
    "copy_sql = '''COPY \"analytics_tables\".uconnect_lead_form_outside_sources(column_list)\n",
    "            from 'HubSpot-Imports.csv' \n",
    "            delimiter ',';\n",
    "            '''\n",
    "\n",
    "with open('HubSpot-Imports.csv', 'r') as f:\n",
    "    cur.copy_expert(sql=copy_sql, file=f)\n",
    "    conn.commit()\n",
    "    cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to db\n",
    "\n",
    "import sqlalchemy as sa\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('HubSpot-Imports.csv')\n",
    "engine = sa.create_engine('postgresql://awsdatapipeline:Know.it.13818@udacity-segment.c2zpsqalam7o.us-west-2.redshift.amazonaws.com:5439/analytics')\n",
    "#engine = sa.create_engine('postgresql://udacian:AYEe&mtihMqtXQbWR2xgWrhmKzd6%5DF@udacity-segment.c2zpsqalam7o.us-west-2.redshift.amazonaws.com:5439/analytics')\n",
    "df.to_sql('analytics_tables.uconnect_lead_form_outside_sources',engine,index = False,if_exists = 'replace')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_sql(engine, df, table, if_exists='fail', sep='\\t', encoding='utf8'):\n",
    "    import StringIO\n",
    "    # Create Table\n",
    "    df[:0].to_sql(table, engine, index = False, if_exists=if_exists)\n",
    "\n",
    "    # Prepare data\n",
    "    output = StringIO.StringIO()\n",
    "    df.to_csv(output, sep=sep, header=False, encoding=encoding)\n",
    "    output.seek(0)\n",
    "\n",
    "    # Insert data\n",
    "    connection = engine.raw_connection()\n",
    "    cursor = connection.cursor()\n",
    "    cursor.copy_from(output, table, sep=sep, null='')\n",
    "    connection.commit()\n",
    "    cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument 1 must have both .read() and .readline() methods",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-ffb81aed91e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcursor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'analytics_tables.uconnect_lead_form_outside_sources'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnull\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: argument 1 must have both .read() and .readline() methods"
     ]
    }
   ],
   "source": [
    "connection = engine.raw_connection()\n",
    "cursor = connection.cursor()\n",
    "cursor.copy_from(df, 'analytics_tables.uconnect_lead_form_outside_sources', sep=',', null='')\n",
    "cursor.copy_expert(\"copy quote_location from stdin (format csv)\", location_file)\n",
    "connection.commit()\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'StringIO'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-0fae56028d4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'HubSpot-Imports.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'postgresql://awsdatapipeline:Know.it.13818@udacity-segment.c2zpsqalam7o.us-west-2.redshift.amazonaws.com:5439/analytics'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mto_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'analytics_tables.uconnect_lead_form_outside_sources'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mif_exists\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-86db0b4a101b>\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(engine, df, table, if_exists, sep, encoding)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mto_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_exists\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fail'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Create Table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_exists\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mif_exists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'StringIO'"
     ]
    }
   ],
   "source": [
    "import sqlalchemy as sa\n",
    "import pandas as pd\n",
    "df = pd.read_csv('HubSpot-Imports.csv')\n",
    "engine = sa.create_engine('postgresql://awsdatapipeline:Know.it.13818@udacity-segment.c2zpsqalam7o.us-west-2.redshift.amazonaws.com:5439/analytics')\n",
    "to_sql(engine,df,'analytics_tables.uconnect_lead_form_outside_sources',sep=',',if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#admissions api connection\n",
    "import sqlalchemy as sa\n",
    "engine = sa.create_engine('redshift+psycopg2://admissionsapi:admissionsapi@admissions-api.cv90snkxh2gd.us-west-2.rds.amazonaws.com:5432/admissionsapi')\n",
    "pd.read_sql(\"select * from applicants limit 10\",engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# not working\n",
    "import sqlalchemy as sa\n",
    "engine = sa.create_engine('postgresql://analytics:!TgP$Ol9Z&6QhKW0tmn9mOW5rYT2J8@analytics.cv90snkxh2gd.us-west-2.rds.amazonaws.com:5432/analytics')\n",
    "\n",
    "def csv_to_db(f):\n",
    "    f.to_sql('question_responses2', engine, schema='test_admissions', if_exists='append')\n",
    "    \n",
    "chunks = pd.read_csv('question_responses_history2.csv', sep=',', chunksize=10)\n",
    "\n",
    "from multiprocessing import Pool\n",
    "p = Pool(10)\n",
    "\n",
    "p.map(csv_to_db, chunks)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql_apps = \"select a.id as application_id,a.applicant_id,a.first_name,a.last_name,a.email\\\n",
    "                  ,coalesce(a.applicant_geo,'Unknown') AS applicant_geo\\\n",
    "                  ,coalesce(a.applicant_country,'Unknown') AS applicant_country\\\n",
    "                   from applications a\\\n",
    "                   where a.submitted_at is not null and a.cohort_id = '326' and application_status = 'in_review'\"\n",
    "df = pd.read_sql(sql_apps,conn_laurel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql_questions = \"select application_id,question_prompt,response\\\n",
    "                 from admissions.question_responses qr\\\n",
    "                 inner join applications a on qr.application_id = a.id\\\n",
    "                 where a.cohort_id = '326'\\\n",
    "                   and a.submitted_at is not null\\\n",
    "                   and a.application_status = 'in_review'\"\n",
    "df_2 = pd.read_sql(sql_questions,conn_laurel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "questions_pivot = df_2.pivot(index='application_id', values='response', columns='question_prompt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joined = df.join(questions_pivot, on='application_id')\n",
    "final = joined[joined.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final.to_csv('cohort326.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joined.to_csv('cohort326.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
